---
title: This is what I learned during summer
subtitle: Experiences about my first nanodegree
category: learning
header-url: https://images.unsplash.com/photo-1481627834876-b7833e8f5570?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1900&fit=crop&s=3ac10482bdcb8f7bd75f63617b48e58c
photo-author: Janko Ferlič
photo-author-profile: thepootphotographer
---

So, it seems I have reached my first goal since the [Great Turning Point](http://dotkomblog.com/life/2017/07/18/changes/) this summer: today I received my certification for the data analyst nanodegree on Udacity. It was not the greatest challenge of all times, nevertheless it feels good to pass even such a smaller milestone.

It took little longer than I anticipated, even when accounting for the short summer holiday, but as I didn't have any previous examples, my first guess was not a reliable benchmark anyway. I managed to fit the whole thing into two months, and still have some life besides learning.

![](/img/posts/nanodegree.png)

## What did I learn?

Even though I considered this course a _’refresher’_, I did learn quite a few new things. Here are the key takeaways:

- __This was a good idea:__ After spending the better part of the summer with data crunching, coding stats and drawing charts, I am even more excited about all these things than before. The experiment was succesful, the subject is still alive!
- __Refreshed theoretical background:__ Though I learnt lots of stats and econometrics (I'm an economist and investment analyst after all), I haven’t been using that in the past few years as a manager. Now I have some working knowledge again and a general understanding of the directions I am yet to explore.
- __Practical Python skills:__ I already used tools like `pandas`, `scipy`, `pyplot` or Jupyter notebooks before, but I explored them even further. I am considerably faster now and write code in a more _pythonic_ way.
- __New tools:__ I never tried R before, and even though I had my [fair share of struggles](http://dotkomblog.com/coding/2017/08/01/first-time-with-r/) with it, I think I see where it fits into the data science world. Also since I finished my project with Tableau I just keep asking myself _’Why didn’t I use this before?’_. I will write about this later.
- __Sneak peek into Machine Learning:__ That was the main goal: take a look into this enormous field without getting too deep, too fast. It worked and now I have a more nuanced overview in general, I can translate (some) questions into (basic) machine learning problems, and I have practical understanding of `scikit-learn`.
- __Realizing how much I don’t know:__ I had nice revelations and felt success along the way, but the most important takeaway is that I am still just scracthing the surface of data science (and especially machine learning). But the good news is that I have all the means to dig deeper!

I think I will write at least one or two mosre posts about the actual projects and share the results in some form.

## How long did it take?

During the two months from July 11 to September 13, I have spent close to 140 hours in total with the course materials and completing the projects (I tracked time with [Harvest](https://www.getharvest.com/) and its Trello _power-up_). This all translates to more than 15 hours a week, slightly, but not disapointingly less than I initially planned for. 

This is the actual (net) time I was working on the course (or tried very hard), not including casual reading in the subject, playing with the new tools on my own, or writing blog posts about it. Unfortunately I did not measure the projects separately from their courses, but for most of the modules the _'homework'_ took the majority of the time.

Obviously _Intro to Machine Learning_ was the most complex one, and also the course materials were quite lengthy. I spent at 30 hours of it on the project trying to predict which stakeholder might be a _person of interest_ in the famous Enron fraud case by using some financial data and their emailing statistics. That was challenging for me, but enjoyed it (most of the time).

The _Exploratory Data Analysis_ also took long (28 hours), but this was more about the tool than the content. It was mandatory to complete the project in R and RStudio. The other modules can be finished in a matter of week or even a in a few days.

<div class='tableauPlaceholder' id='viz1505371559836' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;ud&#47;udacity_dand_time&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='site_root' value='' /><param name='name' value='udacity_dand_time&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;ud&#47;udacity_dand_time&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='filter' value='publish=yes' /></object></div>                
<script type='text/javascript'>                    var divElement = document.getElementById('viz1505371559836');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>


It’s also interesting to see how my enthusiasm decreased during the time: I started with spending at least a few hours on the nanodegree for _12 consecutive days_, sometimes clocking in even 6-7 hours, jumping into the next project the same day I passed the previous. I only missed four days out of 20.

But that’s exhausting, and does not leave much room for other activites. The pace of the second half of August seems more sustainable, leaving out a few days, and only putting in around 4 hours a day when doing longer streaks. I guess that’s what I should be aiming for in the future.

## What would I do differently?

In general I'm satisfied how it went. In hindsight I might have spent more time on the course materials than it was absolutely necessary, because I didn’t want to miss any important parts (I was playing the videos on 1.25x or 1.5x speed anyway). But I think my future courses will be more difficult, so this is not going to be an issue anymore.

Also for a few projects I felt I put in more than the minimum requirements (even though not all my projects met expectations for the first submission). But my goal was to learn these things, not to barely pass as fast as I can, so none of the extra hours were wasted (and I am not even sure there were that many 'extra’ hours, maybe that’s exactly what it takes to complete these things).

## What’s next?

My plans have not changed much, I am aiming for the Machine Learning nanodegree on Udacity. I think it will need much more time than the Data Analyst Nanodegree, but I haven’t done any estimations yet. But before that I need a little break (a few days maybe a week) to catch up on some other private projects I was ignoring in the past few weeks.

If you happen to have any experiences with similar courses, share it! I'm very open to feedback.
