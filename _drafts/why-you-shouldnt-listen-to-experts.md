---
title: Why you shouldn’t listen to experts
subtitle: And use data instead
---

This summer, just two days before departure we cancelled our holiday trip to Italy, because the doctor advised my then few-weeks pregnant wife to avoid flying. The reason was a blurry little something they saw on the ultrasound (I mean, besides our future child, who was also a blurry little something at that point) which, according to the same doctor, was quite common and would most probably disappear without any noticable effect. 

‘No need to worry, but you should skip the trip’ - said the doctor. We readily complied, and never regretted it for a second. We had been planning all along with this possibility in mind and only booked things we could freely cancel anytime (a benefit of marrying someone in the airline industry). And then we went for a wonderful week in the countryside.

But so many common fallacies were packed into this single case that it bugged my analytical mind. Was it really how it should work? 

_(Even though I immediately wrote this piece, I did superstitiously wait for the 12th week to publish it. So much for being very rational.)_

## You want to avoid loss at any costs

Obviously we felt that a short (and not quite exotic) holiday in the Mediterranian wasn’t worth the risk of any issues with the pregnancy. Sounds reasonable, doesn’t it? But what if we could have known the _exact_ risk? Like there were some issues in exactly 1 in a million similar cases? Or 1 in a billion? Could this change our minds? I think it would have helped.

On the other hand many studies proved that human brain is wired for loss-aversion. It forces us to chose scenarios where the perceived loss is lower, even when the expected value (the sum of outcomes, each weighted by its probability) is much worse than in other alternatives. We want to avoid losing our future child so we act accordingly even if it has equal chance to being hit by an asteroid with a rainbow-colored unicorn named Jeff riding on it.

Perhaps the probabilities were many order of magnitude higher, but as I cannot tell you the ‘value’ of (not) having issues when expecting a baby, I cannot tell you what percentage we would have considered ‘acceptable’ risk either (and you rarely get those numbers anyway, more on that later). It’s just impossible to exactly ’price in’ things like that.

## You cannot handle probabilities

The human mind is not prepared to work with probabilistic outcomes and think of expected values. Our ancestors did not want to assess the chances of being slaughtered by a sabertooth tiger on a statistical basis, let alone repeat the same experiment thousand times to have a fair understanding of the probability distribution. Most of them just ran away, and the remaining prehistoric statisticians fell victim to natural selection.

It works the other way around, too. We buy lottery tickets or invest in lottery-like securities for the promise of extreme payout with extreme low probability. Think of a biotech penny stock in the verge of bankrupcy that might succefully finish the clinical tests of its only - but hopefully lifechanging - product at some unspecified time in the future. There are people investing in things like that.

So we are in general very bad at assessing tail-risks and expected values, especially when it includes lot of factors. Of course our case was not a typical everyday dilemma, but we react similarly to smaller common problems. And huge businesses are built upon these fallacies.

## The expert is no better

Also we faced a special agent-problem with our ‘expert’, the doctor. It was not his fault, we all have the same issue with almost all the experts we tend to rely upon. I suspect our widely known and renowned professor did not tell us any estimations about the risks we faced because simply he also didn’t know. But it is not an option for him to admit it. 

Should something bad really happen during a trip he approved he would not be able to explain that the issue was not related to it (he wouldn’t even know himself). So he followed his loss-averse instincts and made the rational decision of tossing the risk around. This way it was our call to make the trip _against_ his advise, but how would _I_ know that all this caution was just unnecessary?

We like the doctor as he is very good at lots of things, but his professional experience and academic knowledge does not make him a prophet. Things that might happen in the body of a pregnant woman under special circumstances is too complex to predict in details with the rudimentary _expert opinions_ that are still widely present in healthcare (except when the symptoms are quite obvious). 

## They don’t know what will happen

But the expert problem is present on the other end of the scale, too. Just think of stock market pundits. Noone says _’Take your time, and let us know if you happened to figure out something with reasonable probabilities attached to it. It doesn’t matter if you can come up with something only once a year.’_ You have to say something specific and certain about the future _all the time_. That’s why experts resort to using clichés and professional language that might sound very knowledgable but in fact is pure gibberish. I know, I was part of it.

It is also like buying lottery tickets: maybe you get lucky and nail something important in advance, that will make you _The Expert_. The pay-off can be huge while being wrong is quite okay if you wrapped your message in proper amount of bullshit. So many market experts try to make as many long shots as possible, hoping that they hit the target once.

## So no experts?

So experts are not exempt from all the psychological pitfalls every human have to deal with. Still, it does not necessarily mean we should completely avoid them. We and they just have to find out how to make use of their contribution.

<iframe src="//coub.com/embed/wc7lq?muted=false&autostart=false&originalSize=false&startWithHD=false" allowfullscreen="true" frameborder="0" width="640" height="360"></iframe>

The doctors have always provided important service by _explaining_ the _current_ condition of a patient (besides treating more or less obvious cases based on their special folklore), a good stock market analyst could give you _comprehensive account_ of the _current_ state of a company or industry, and so on. You just shouldn’t expect them to tell the future or deeply analyse all the available options in their entirety.

The ultimate solution is data. Maybe if the advice for us came in a form of _’in XX thousand cases flying caused minor issues in 0.00X% and major issues in 0.000X% of the cases for pregnant women with similar condition, and when a certain action made, these rates fell by XX%’_, we would have made the same decision, but it would have been much more educated and sound.

Or better, imagine that the advice for us about flying or not was based a result of a model that _continuously_ evaluates hundreds of different external and internal factors about the body of the mother (obtained through wearable or even implanted devices) and compares it to a vast database of pregnant women under different circumstances all around the world. It’s not even sci-fi.

## AI needs humans

It all means no more ‘expert’ guesses, and maybe a little less irrationality in everyday decision-making by facing clear probabilities and expected values (loss-aversion and other fallacies can still kick in). But for a long-long time we will still need human experts to build, finetune, operate and explain the work of artificial intelligence. 

This also means that the segment threatened the most by the looming revolution of AI is the experts in every field, but also they can benefit the most from transferring their expertise to artificial intelligence. And while industrial automation and replacement of human workforce has been a trend for decades, for the well-educated experts this is still something new.
